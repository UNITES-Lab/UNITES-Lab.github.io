<!DOCTYPE html>
<html lang="en">

<head>
    <title>UNITES Lab</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="view-transition" content="same-origin">

    <link href="https://fonts.googleapis.com/css?family=B612+Mono|Cabin:400,700&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="fonts/icomoon/style.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
          integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">

    <link rel="stylesheet" href="css/jquery-ui.css">
    <link rel="stylesheet" href="css/owl.carousel.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">

    <link rel="stylesheet" href="css/jquery.fancybox.min.css">

    <link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">

    <link rel="stylesheet" href="css/aos.css">
    <link href="css/jquery.mb.YTPlayer.min.css" media="all" rel="stylesheet" type="text/css">

    <link rel="stylesheet" href="css/style.css">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->


</head>

<body data-spy="scroll" data-target=".site-navbar-target" data-offset="300">

<div class="site-wrap">

    <div class="site-mobile-menu site-navbar-target">
        <div class="site-mobile-menu-header">
            <div class="site-mobile-menu-close mt-3">
                <span class="icon-close2 js-menu-toggle"></span>
            </div>
        </div>
        <div class="site-mobile-menu-body"></div>
    </div>

    <div class="header-top">
        <div class="container" style="padding:20px">
            <div class="d-flex align-items-center">
                    <img src="./logo.png" width="15%">
                    <a class="site-logo" style="margin-left: 15px; font-size: 1.8rem;">
                             <b style="color: rgb(71, 71, 71)">U</b>niversity of <b style="color: rgb(71, 71, 71)">N</b>orth Carolina, A<b style="color: rgb(71, 71, 71)">I</b> <b style="color: rgb(71, 71, 71)">T</b>rustworthiness, <b style="color: rgb(71, 71, 71)">E</b>fficiency, and for <b style="color: rgb(71, 71, 71)">S</b>cience
                    </a>
                    <a href="#"
                       class="ml-auto d-inline-block d-lg-none site-menu-toggle js-menu-toggle text-black"><span
                            class="icon-menu h3"></span></a>
            </div>
        </div>
    </div>


    <div class="site-navbar py-2 js-sticky-header site-navbar-target d-none pl-0 d-lg-block" role="banner">

        <div class="container" style="padding-right=10%">
            <div class="d-flex align-items-right">
                <div class="ml-auto">
                    <nav class="site-navigation position-relative text-right" role="navigation">
                        <ul class="site-menu main-menu js-clone-nav mr-auto d-none pl-0 d-lg-block">
                            <li class="active">
                                <a href="index.html" class="nav-link text-right">Home</a>
                            </li>
                            <li>
                                <a href="research.html" class="nav-link text-left">PI & Research</a>
                            </li>
                            <li>
                                <a href="publication.html" class="nav-link text-left">Publication</a>
                            </li>
                            <li>
                                <a href="group.html" class="nav-link text-left">Group</a>
                            </li>
                            <li>
                                <a href="resource.html" class="nav-link text-left">Resource</a>
                            </li>
                            <li>
                                <a href="gallery.html" class="nav-link text-left">Gallery</a>
                            </li>
                            <!-- <li>
                                <a href="prospective_students.html" class="nav-link text-left">Opening</a>
                            </li> -->
                        </ul>
                    </nav>

                </div>

            </div>
        </div>

    </div>

</div>



<div class="site-section">
    <div class="container">
        <div class="row">
            <div class="col-lg-12">
                <div class="section-title" style="margin-bottom:20px">
                    <h2>Publication</h2>
                </div>
                <p>Our group actively publishes in the fields of machine learning, computer vision, natural language processing, and AI for science. For an up-to-date full paper list, please visit <a href="https://scholar.google.com/citations?user=LE3ctn0AAAAJ">Dr. Chen's Google Scholar</a>.</p>

                <p style="margin-top: 15px;"><b>Quick Navigation:</b>
                    <a href="#efficient-dl">Efficient Deep Learning</a> |
                    <a href="#trustworthy-ai">Trustworthy AI</a> |
                    <a href="#llm">Large Language Models</a> |
                    <a href="#ai-science">AI for Science</a> |
                    <a href="#cv-multimodal">Computer Vision & Multimodal</a>
                </p>
            </div>
        </div>

        <!-- Efficient Deep Learning -->
        <div class="row" style="margin-top: 40px;">
            <div class="col-lg-12" id="efficient-dl">
                <div class="section-title" style="margin-bottom:20px">
                    <h2>Efficient Deep Learning & Sparse Neural Networks</h2>
                </div>
                <div class="trend-entry">
                    <div class="trend-contents">
                        <ul>
                            <li><b>[NeurIPS'25]</b> Mozart: Modularized and Efficient MoE Training on 3.5D Wafer-Scale Chiplet Architectures<br>
                            <span style="color:#666; font-size:0.9em;">S Luo*, Y Han*, P Li*, J Qin*, J Peng, YK Zhao, Y Cao, T Chen</span></li>

                            <li><b>[ICML'25]</b> Occult: Optimizing Collaborative Communication across Experts for Accelerated Parallel MoE Training and Inference<br>
                            <span style="color:#666; font-size:0.9em;">S Luo, P Li, J Peng, H Wang, Y (Katie) Zhao, Y (Kevin) Cao, Y Cheng, T Chen</span></li>

                            <li><b>[ICML'25]</b> I2MoE: Interpretable Multimodal Interaction-aware Mixture-of-Experts<br>
                            <span style="color:#666; font-size:0.9em;">J Xin, S Yun, J Peng, I Choi, JL Ballard, T Chen, Q Long</span></li>

                            <li><b>[NAACL'25 SAC Award]</b> Advancing MoE Efficiency: A Collaboration-Constrained Routing (C2R) Strategy for Better Expert Parallelism Design<br>
                            <span style="color:#666; font-size:0.9em;">M Zhang*, P Li*, J Peng, M Qiu, T Chen</span></li>

                            <li><b>[ICLR'25]</b> PortLLM: Personalizing Evolving Large Language Models with Training-Free and Portable Model Patches<br>
                            <span style="color:#666; font-size:0.9em;">R Shahroz Khan, P Li*, S Yun*, Z Wang, S Nirjon, CW Wong, T Chen</span></li>

                            <li><b>[ICLR'25]</b> Cut the Crap: An Economical Communication Pipeline for LLM-based Multi-Agent Systems<br>
                            <span style="color:#666; font-size:0.9em;">G Zhang, Y Yue, Z Li, S Yun, G Wan, K Wang, D Cheng, JX Yu, T Chen</span></li>

                            <li><b>[EMNLP'25 Findings]</b> Bag of Tricks for Sparse Mixture-of-Experts: A Benchmark Across Reasoning, Efficiency, and Safety<br>
                            <span style="color:#666; font-size:0.9em;">M Qiu, Z Shen, P Li, A Li, T Chen</span></li>

                            <li><b>[NeurIPS'24]</b> Model-GLUE: Democratized LLM Scaling for A Large Model Zoo in the Wild<br>
                                <span style="color:#666; font-size:0.9em;">X Zhao*, G Sun*, R Cai*, Y Zhou*, P Li*, P Wang*, B Tan, Y He, L Chen, Y Liang, B Chen, B Yuan, H Wang, A Li, Z Wang, T Chen</span></li>

                            <li><b>[EMNLP'24]</b> FFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed Forward Skipping<br>
                            <span style="color:#666; font-size:0.9em;">A Jaiswal, B Hu, L Yin, Y Ro, S Liu, T Chen, A Akella</span></li>

                            <li><b>[EMNLP'24]</b> Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning<br>
                            <span style="color:#666; font-size:0.9em;">A Bandari, L Yin, CY Hsieh, AK Jaiswal, T Chen, L Shen, R Krishna, S Liu</span></li>

                            <li><b>[ICML'24]</b> Revisiting Zeroth-Order Optimization for Memory-Efficient LLM Fine-Tuning: A Benchmark<br>
                            <span style="color:#666; font-size:0.9em;">Y Zhang*, P Li*, J Hong*, J Li*, Y Zhang, W Zheng, PY Chen, JD Lee, W Yin, M Hong, Z Wang, S Liu, T Chen</span></li>

                            <li><b>[ICML'24]</b> Two Heads Are Better Than One: Boosting Graph Sparse Training via Semantic and Topological Awareness<br>
                            <span style="color:#666; font-size:0.9em;">G Zhang, Y Yue, K Wang, J Fang, Y Sui, K Wang, Y Liang, D Cheng, S Pan, T Chen</span></li>

                            <li><b>[ICML'24]</b> Towards Building Reliable Language Models with Sparse Mixture-of-Experts<br>
                            <span style="color:#666; font-size:0.9em;">G Chen, X Zhao, T Chen, Y Cheng</span></li>

                            <li><b>[ICLR'24]</b> Merge, Then Compress: Demystify Efficient SMoE with Hints from Its Routing Policy<br>
                            <span style="color:#666; font-size:0.9em;">P Li, Z Zhang, P Yadav, YL Sung, Y Cheng, M Bansal, T Chen</span></li>

                            <li><b>[ICLR'24]</b> Sparse MoE with Language Guided Routing for Multilingual Machine Translation<br>
                            <span style="color:#666; font-size:0.9em;">X Zhao, X Chen, Y Cheng, T Chen</span></li>

                            <li><b>[AAAI'25]</b> Sparse Transfer Learning Accelerates and Enhances Certified Robustness: A Comprehensive Study<br>
                            <span style="color:#666; font-size:0.9em;">Z Li, T Chen, L Li, B Li, Z Wang</span></li>

                            <li><b>[AAAI'25]</b> Visual Prompting Upgrades Neural Network Sparsification: A Data-Model Perspective<br>
                            <span style="color:#666; font-size:0.9em;">C Jin*, T Huang*, Y Zhang, M Pechenizkiy, S Liu, S Liu, T Chen</span></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Trustworthy AI -->
        <div class="row" style="margin-top: 40px;">
            <div class="col-lg-12" id="trustworthy-ai">
                <div class="section-title" style="margin-bottom:20px">
                    <h2>Trustworthy AI & Safety</h2>
                </div>
                <div class="trend-entry">
                    <div class="trend-contents">
                        <ul>
                            <li><b>[COLM'25]</b> More is Less: The Pitfalls of Multi-Model Synthetic Preference Data in DPO Safety Alignment<br>
                            <span style="color:#666; font-size:0.9em;">Y Wang, R Chen, B Li, D Cho, Y Deng, R Zhang, T Chen, Z Wang, A Grama, J Hong</span></li>

                            <li><b>[EMNLP'25]</b> Bit-Flip Error Resilience in LLMs: A Comprehensive Analysis and Defense Framework<br>
                            <span style="color:#666; font-size:0.9em;">Y Chen, Z Tan, AK Jaiswal, H Qu, X Zhao, Q Lin, Y Cheng, A Kwong, Z Cao, T Chen</span></li>

                            <li><b>[KDD'25]</b> A Survey on Trustworthy LLM Agents: Threats and Countermeasures<br>
                            <span style="color:#666; font-size:0.9em;">M Yu*, F Meng*, X Zhou, S Wang, J Mao, L Pang, T Chen, K Wang, X Li*, Y Zhang, B An, Q Wen*</span></li>

                            <li><b>[ACL'25 Findings]</b> Unveiling Privacy Risks in Multi-Modal Large Language Models: Task-Specific Vulnerabilities and Mitigation Challenges<br>
                            <span style="color:#666; font-size:0.9em;">T Chen, P Li, K Zhou, T Chen, H Wei</span></li>

                            <li><b>[ACL'25 Findings]</b> Vision Language Model Helps Private Information De-Identification in Vision Data<br>
                            <span style="color:#666; font-size:0.9em;">T Chen, P Li, K Zhou, T Chen, H Wei</span></li>

                            <li><b>[NAACL'25]</b> BPO: Towards Balanced Preference Optimization between Knowledge Breadth and Depth in Alignment<br>
                            <span style="color:#666; font-size:0.9em;">S Wang, Y Tong, H Zhang, D Li, X Zhang, T Chen</span></li>

                            <li><b>[NAACL'25]</b> Layer-Level Self-Exposure and Patch: Affirmative Token Mitigation for Jailbreak Attack Defense<br>
                            <span style="color:#666; font-size:0.9em;">Y Ouyang, H Gu, S Lin, W Hua, J Peng, B Kailkhura, T Chen, K Zhou</span></li>

                            <li><b>[AAAI'25]</b> Tuning-Free Accountable Intervention for LLM Deployment--A Metacognitive Approach<br>
                            <span style="color:#666; font-size:0.9em;">Z Tan, J Peng, T Chen, H Liu</span></li>

                            <li><b>[AAAI'25]</b> Sparsity-Guided Holistic Explanation for LLMs with Interpretable Inference-Time Intervention<br>
                            <span style="color:#666; font-size:0.9em;">Z Tan, T Chen, Z Zhang, H Liu</span></li>

                            <li><b>[EAAI'25]</b> Word-Sequence Entropy: Towards Uncertainty Estimation in Free-Form Medical Question Answering Applications and Beyond<br>
                            <span style="color:#666; font-size:0.9em;">Z Wang, J Duan, C Yuan, Q Chen, T Chen, Y Zhang, R Wang, X Shi, K Xu</span></li>

                            <li><b>[EMNLP'24]</b> "Glue Pizza and Eat Rocks"--Exploiting Vulnerabilities in Retrieval-Augmented Generative Models<br>
                            <span style="color:#666; font-size:0.9em;">Z Tan, C Zhao, R Moraffah, Y Li, S Wang, J Li, T Chen, H Liu</span></li>

                            <li><b>[ICML'24]</b> TrustLLM: Trustworthiness in Large Language Models<br>
                            <span style="color:#666; font-size:0.9em;">Y Huang, L Sun, H Wang, S Wu, Q Zhang, Y Li, C Gao, Y Huang, W Lyu, Y Zhang, et al.</span></li>

                            <li><b>[SDM'25]</b> Protecting Privacy against Membership Inference Attack with LLM Fine-tuning through Flatness<br>
                            <span style="color:#666; font-size:0.9em;">T Chen, L Da, H Zhou, P Li, K Zhou, T Chen, H Wei</span></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Large Language Models -->
        <div class="row" style="margin-top: 40px;">
            <div class="col-lg-12" id="llm">
                <div class="section-title" style="margin-bottom:20px">
                    <h2>Large Language Models & Agents</h2>
                </div>
                <div class="trend-entry">
                    <div class="trend-contents">
                        <ul>
                            <li><b>[EMNLP'25 Oral]</b> EQA-RM: A Generative Embodied Reward Model with Test-time Scaling<br>
                            <span style="color:#666; font-size:0.9em;">Y Chen, Z Tan, T Chen</span></li>

                            <li><b>[EMNLP'25]</b> Task-Aware Resolution Optimization for Visual Large Language Models<br>
                            <span style="color:#666; font-size:0.9em;">W Luo, Z Tan, Y Li, X Zhao, K Lee, B Dariush, T Chen</span></li>

                            <li><b>[EMNLP'25]</b> MedHallu: A Comprehensive Benchmark for Detecting Medical Hallucinations in Large Language Models<br>
                            <span style="color:#666; font-size:0.9em;">S Pandit, J Xu, J Hong, Z Wang, T Chen, K Xu, Y Ding</span></li>

                            <li><b>[EMNLP'25 Findings]</b> ORAL: Prompting Your Large-Scale LoRAs via Conditional Recurrent Diffusion<br>
                            <span style="color:#666; font-size:0.9em;">R Shahroz, D Tang, P Li, K Wang, T Chen</span></li>

                            <li><b>[EMNLP'25 Findings]</b> FIER: Fine-Grained and Efficient KV Cache Retrieval for Long-context LLM Inference<br>
                            <span style="color:#666; font-size:0.9em;">D Wang, Z Liu, S Wang, Y Ren, J Deng, J Hu, T Chen, H Yang</span></li>

                            <li><b>[ICML'25 Spotlight]</b> G-Designer: Architecting Multi-Agent Communication Topologies via Graph Neural Networks<br>
                            <span style="color:#666; font-size:0.9em;">G Zhang, Y Yue, X Sun, G Wan, M Yu, J Fang, K Wang, T Chen, D Cheng</span></li>

                            <li><b>[ACL'25]</b> In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents<br>
                            <span style="color:#666; font-size:0.9em;">Z Tan, J Yan, IH Hsu, R Han, Z Wang, LT Le, Y Song, Y Chen, H Palangi, G Lee, A Iyer, T Chen, H Liu, CY Lee, T Pfister</span></li>

                            <li><b>[ACL'25]</b> The Efficiency vs. Accuracy Trade-off: Optimizing RAG-Enhanced LLM Recommender Systems Using Multi-Head Early Exit<br>
                            <span style="color:#666; font-size:0.9em;">H Zhou, H Gu, X Liu, K Zhou, M Liang, Y Xiao, S Govindan, P Chawla, J Yang, X Meng, H Li, B Zhang, L Luo, WY Chen, Y Han, B Long, R Zhang, T Chen</span></li>

                            <li><b>[ACL'25 Findings]</b> UQ-Merge: Uncertainty Guided Multimodal Large Language Model Merging<br>
                            <span style="color:#666; font-size:0.9em;">H Qu, X Zhao, J Peng, K Lee, B Dariush, T Chen</span></li>

                            <li><b>[NAACL'25]</b> GuideLLM: Exploring LLM-Guided Conversation with Applications in Autobiography Interviewing<br>
                            <span style="color:#666; font-size:0.9em;">J Duan*, X Zhao*, Z Zhang*, E Ko, L Boddy, C Wang, T Li, A Rasgon, J Hong, MK Lee, C Yuan, Q Long, Y Ding, T Chen, K Xu</span></li>

                            <li><b>[NeurIPS'24]</b> GTBench: Uncovering the Strategic Reasoning Capabilities of LLMs via Game-Theoretic Evaluations<br>
                            <span style="color:#666; font-size:0.9em;">J Duan*, R Zhang*, J Diffenderfer, B Kailkhura, L Sun, E Stengel-Eskin, M Bansal, T Chen, K Xu</span></li>

                            <li><b>[NAACL'24]</b> ReTA: Recursively Thinking Ahead to Improve the Strategic Reasoning of Large Language Models<br>
                            <span style="color:#666; font-size:0.9em;">J Duan, S Wang, J Diffenderfer, L Sun, T Chen, B Kailkhura, K Xu</span></li>

                            <li><b>[EACL'24]</b> Contextualization Distillation from Large Language Model for Knowledge Graph Completion<br>
                            <span style="color:#666; font-size:0.9em;">D Li, Z Tan, T Chen, H Liu</span></li>

                            <li><b>[ICLR'25]</b> Adapt-âˆž: Scalable Lifelong Multimodal Instruction Tuning via Dynamic Data Selection<br>
                            <span style="color:#666; font-size:0.9em;">A Maharana*, J Yoon*, T Chen, M Bansal</span></li>

                            <li><b>[COLING'25]</b> Aurora-M: The First Open Source Multilingual Language Model Red-Teamed According to the US Executive Order<br>
                            <span style="color:#666; font-size:0.9em;">T Nakamura, M Mishra, S Tedeschi, Y Chai, JT Stillerman, F Friedrich, P Yadav, T Laud, VM Chien, TY Zhuo, D Misra, B Bogin, XS Vu, M Karpinska, AV Dantuluri, W Kusa, T Furlanello, R Yokota, N Muennighoff, S Pai, T Adewumi, V Laippala, X Yao, A Junior, A Ariyak, A Drozd, J Clive, K Gupta, L Chen, Q Sun, K Tsui, N Persaud, N Fahmy, T Chen, M Bansal, N Monti, T Dang, Z Luo, TT Bui, R Navigli, V Mehta, M Blumberg, V May, H Nguyen, S Pyysalo</span></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- AI for Science -->
        <div class="row" style="margin-top: 40px;">
            <div class="col-lg-12" id="ai-science">
                <div class="section-title" style="margin-bottom:20px">
                    <h2>AI for Science & Healthcare</h2>
                </div>
                <div class="trend-entry">
                    <div class="trend-contents">
                        <ul>
                            <li><b>[Nature Plants'25]</b> Using Large Language Models to Address the Bottleneck of Georeferencing Natural History Collections<br>
                            <span style="color:#666; font-size:0.9em;">Y Xie, DS Park, MA Sinnott-Armstrong, J Ho, T Chen, AS Weakley, LJ Aguirre Lopez, J Choi, MM Laitinen, NA Steeves, CH Huang, R Xu, X Feng</span></li>

                            <li><b>[ACL'25]</b> MMOFA: A Multi-Omics Foundation Model with Feature-Alignment for Clinical Phenotype Prediction<br>
                            <span style="color:#666; font-size:0.9em;">D Li, Y Yue, R Zhang, Z Tan, T Chen, J Xie, L Bao, D Cheng, H Liu</span></li>

                            <li><b>[KDD'25]</b> Graph Learning under Distribution Shifts: Graph Feature Imputation and Out-of-Distribution Detection<br>
                            <span style="color:#666; font-size:0.9em;">Y Yue, L Yang, Y Li, K Wang, T Chen, Y Sui, D Cheng</span></li>

                            <li><b>[JBI'25]</b> GatorCLR: Personalized Predictions of Patient Outcomes on Electronic Health Records via Similarity-based Contrastive Learning<br>
                            <span style="color:#666; font-size:0.9em;">D Li, C Yuan, R Zhang, N Shang, Q Wei, T Chen, Z Lu, Y Wang</span></li>

                            <li><b>[AAAI'25]</b> Learning to Model the Drift of Biological Neural Network Connectivity from Calcium Imaging Observations<br>
                            <span style="color:#666; font-size:0.9em;">C Jin, Y Xu, J Xiao, T Chen, H Liu, S Liu</span></li>

                            <li><b>[NeurIPS'24]</b> Rethinking Improved Privacy-Utility Trade-off with Pre-existing Knowledge for DP Training<br>
                            <span style="color:#666; font-size:0.9em;">Y Yu, Y Yue, B Chen, G Zhang, Y Liu, A Wei, T Chen, J Gao</span></li>

                            <li><b>[EMNLP'24 Findings]</b> Synergizing Large Language Models and Knowledge Graphs for Alzheimer's Disease Care Plan Generation<br>
                            <span style="color:#666; font-size:0.9em;">D Li, Y Yue, R Zhang, Z Tan, Y Guo, X Gong, T Chen, J Xie, D Cheng, H Liu</span></li>

                            <li><b>[EMNLP'24 Findings]</b> Cross-Lingual Multi-Hop Knowledge Editing -- Benchmarks, Analysis and a Simple Contrastive Learning Based Approach<br>
                            <span style="color:#666; font-size:0.9em;">A Khandelwal*, H Singh*, H Gu, T Chen, K Zhou</span></li>

                            <li><b>[ECCV'24]</b> Mew: Multiplexed Immunofluorescence Image Analysis Through an Efficient Multiplex Network<br>
                            <span style="color:#666; font-size:0.9em;">S Yun, J Peng, AE Trevino, C Park, T Chen</span></li>

                            <li><b>[ICML'24]</b> Evolution-Inspired Loss Functions for Protein Representation Learning<br>
                            <span style="color:#666; font-size:0.9em;">T Bepler, S Liu, T Chen, V Gligorijevic</span></li>

                            <li><b>[Bioinformatics'24]</b> Single-cell RNA Sequencing Data Imputation Using Bi-level Feature Propagation<br>
                            <span style="color:#666; font-size:0.9em;">Z Tang, S Li, X Jiang, S Peng, T Chen, S Liu, J Xu</span></li>

                            <li><b>[CVPR'24]</b> Molecular Data Programming: Towards Molecule Pseudo-labeling with Systematic Weak Supervision<br>
                            <span style="color:#666; font-size:0.9em;">W Zhang, J Hong, Y Wang, T Chen, L Getoor</span></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Computer Vision & Multimodal -->
        <div class="row" style="margin-top: 40px;">
            <div class="col-lg-12" id="cv-multimodal">
                <div class="section-title" style="margin-bottom:20px">
                    <h2>Computer Vision & Multimodal Learning</h2>
                </div>
                <div class="trend-entry">
                    <div class="trend-contents">
                        <ul>
                            <li><b>[ACM MM'25 Best Paper]</b> VLM-3R: Vision-Language Models Augmented with Instruction-Aligned 3D Reconstruction<br>
                            <span style="color:#666; font-size:0.9em;">Z Fan*, J Zhang*, R Li, J Zhang, R Chen, H Hu, K Wang, H Qu, D Wang, Z Yan, H Xu, J Theiss, T Chen, J Li, Z Tu, Z Wang, R Ranjan</span></li>

                            <li><b>[ICML'25]</b> Rethinking Multimodal Learning from an Optimization Perspective<br>
                            <span style="color:#666; font-size:0.9em;">S Yun, X Zhao, S Chen, T Chen</span></li>

                            <li><b>[ICML'25]</b> UniTok: A Unified Tokenizer for Visual Generation and Understanding<br>
                            <span style="color:#666; font-size:0.9em;">T Huang, L Zhang, C Jin, S Liu, M Pechenizkiy, S Liu, T Chen</span></li>

                            <li><b>[ICLR'25]</b> What Do Learning Dynamics Reveal About Multimodal Representations?<br>
                            <span style="color:#666; font-size:0.9em;">S Yun, I Choi, J Xin, J Peng, JL Ballard, T Chen, Q Long</span></li>

                            <li><b>[NeurIPS'24 Spotlight]</b> Flex: End-to-End Text-Instructed Visual Navigation with Foundation Models<br>
                            <span style="color:#666; font-size:0.9em;">L Harris, K Ni, A Fishman, T Chen, L Paull, N Roy</span></li>

                            <li><b>[AAAI'25]</b> Visual Prompting Upgrades Neural Network Sparsification: A Data-Model Perspective<br>
                            <span style="color:#666; font-size:0.9em;">C Jin*, T Huang*, Y Zhang, M Pechenizkiy, S Liu, S Liu, T Chen</span></li>

                            <li><b>[ECCV'24]</b> Beyond Accuracy: Tracking More Effective Evolutions in Facial Affective Behavior Analysis<br>
                            <span style="color:#666; font-size:0.9em;">Z Wang, Y Chen, K Zhu, B Jiang, Y Han, T Chen, B Zhang</span></li>

                            <li><b>[CVPR'24]</b> TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models<br>
                            <span style="color:#666; font-size:0.9em;">Y Huang*, R Gong*, J Liu, T Chen, X Liu</span></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Awards -->
        <div class="row" style="margin-top: 40px;">
            <div class="col-lg-12">
                <div class="section-title" style="margin-bottom:20px">
                    <h2>Awards & Honors</h2>
                </div>
                <div class="trend-entry">
                    <div class="trend-contents">
                        <ul>
                            <li><b>[ACM MM'25]</b> Best Paper Award at MFMSI Workshop - VLM-3R: Vision-Language Models Augmented with Instruction-Aligned 3D Reconstruction</li>
                            <li><b>[AMIA-IS'25]</b> Marco Ramoni Distinguished Paper Award - GatorCLR: Personalized Predictions of Patient Outcomes on Electronic Health Records</li>
                            <li><b>[NAACL'25]</b> Low-Resource Methods for NLP SAC Award - Advancing MoE Efficiency: A Collaboration-Constrained Routing Strategy</li>
                            <li><b>[AAAI'25]</b> Best Paper Award at GenAI4Health Workshop</li>
                            <li><b>[NeurIPS'24]</b> Best Demo Paper Award at GenAI4Health Workshop</li>
                            <li><b>1st Place</b> of ACM/IEEE Quantum Computing for Drug Discovery Challenge</li>
                            <li><b>[LoG'22]</b> Best Paper Award - Neural Scaling Laws on Graphs</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

    </div>
</div>

<!-- END section -->


<div class="footer">
    <div class="container">
        <div class="row">
            <div class="col-12">
                <div class="copyright">
                    <p>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        Copyright &copy;<script>document.write(new Date().getFullYear());</script>
                        All rights reserved | Built upon <a
                            href="https://colorlib.com" target="_blank">Colorlib</a>
                        <br>Webpage template borrows from <a href="https://www.vita-group.space/" target="_blank">VITA</a>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        </p>

                </div>
            </div>
        </div>
    </div>
</div>

</div>
<!-- .site-wrap -->


<script src="js/jquery-3.3.1.min.js"></script>
<script src="js/jquery-migrate-3.0.1.min.js"></script>
<script src="js/jquery-ui.js"></script>
<script src="js/popper.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/owl.carousel.min.js"></script>
<script src="js/jquery.stellar.min.js"></script>
<script src="js/jquery.countdown.min.js"></script>
<script src="js/bootstrap-datepicker.min.js"></script>
<script src="js/jquery.easing.1.3.js"></script>
<script src="js/aos.js"></script>
<script src="js/jquery.fancybox.min.js"></script>
<script src="js/jquery.sticky.js"></script>
<script src="js/jquery.mb.YTPlayer.min.js"></script>

<script src="js/main.js"></script>
<script src="js/animations.js"></script>

</body>

</html>
