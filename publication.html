<!DOCTYPE html>
<html lang="en">

<head>
    <title>VITA</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">


    <link href="https://fonts.googleapis.com/css?family=B612+Mono|Cabin:400,700&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="fonts/icomoon/style.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
          integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">

    <link rel="stylesheet" href="css/jquery-ui.css">
    <link rel="stylesheet" href="css/owl.carousel.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">

    <link rel="stylesheet" href="css/jquery.fancybox.min.css">

    <link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">

    <link rel="stylesheet" href="css/aos.css">
    <link href="css/jquery.mb.YTPlayer.min.css" media="all" rel="stylesheet" type="text/css">

    <link rel="stylesheet" href="css/style.css">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->


</head>

<body data-spy="scroll" data-target=".site-navbar-target" data-offset="300">

<div class="site-wrap">

    <div class="site-mobile-menu site-navbar-target">
        <div class="site-mobile-menu-header">
            <div class="site-mobile-menu-close mt-3">
                <span class="icon-close2 js-menu-toggle"></span>
            </div>
        </div>
        <div class="site-mobile-menu-body"></div>
    </div>

    <div class="header-top">
        <div class="container" style="padding:20px">
            <div class="row align-items-center">
                <!-- <div class="col-12 col-lg-6 d-flex"> -->
                    <img src="./logo.png" width="15%">
                    <a class="ml-auto site-logo">
                       
                             &nbsp&nbsp<b style="color: rgb(71, 71, 71)">V</b>isual <b style="color: rgb(71, 71, 71)">I</b>nformatics Group @ University of <b style="color: rgb(71, 71, 71)">T</b>exas at <b style="color: rgb(71, 71, 71)">A</b>ustin
                    </a>
                    <a href="#"
                       class="ml-auto d-inline-block d-lg-none site-menu-toggle js-menu-toggle text-black"><span
                            class="icon-menu h3"></span></a>

                <!-- </div> -->
                <!-- <div class="col-12 col-lg-6 ml-auto d-flex">
                    <div class="ml-md-auto top-social d-none d-lg-inline-block">
                        <a href="#" class="d-inline-block p-3"> </a>
                        <a href="#" class="d-inline-block p-3"> </a>
                        <a href="#" class="d-inline-block p-3"> </a>
                    </div>

                </div> -->
                <!--          <div class="col-6 d-block d-lg-none text-right">-->

            </div>
        </div>
    </div>

    
    <div class="site-navbar py-2 js-sticky-header site-navbar-target d-none pl-0 d-lg-block" role="banner">

        <div class="container" style="padding-right=10%">
            <div class="d-flex align-items-right">
                <!-- <div class="mr-auto">
                    <a href="index.html">
                       <img src="./logo.png" width="10%"/>
                             &nbsp&nbsp<b>V</b>isual <b>I</b>nformatics Group @ University of <b>T</b>exas at <b>A</b>ustin
                    </a>
                </div> -->
                <div class="ml-auto">
                    <nav class="site-navigation position-relative text-right" role="navigation">
                        <ul class="site-menu main-menu js-clone-nav mr-auto d-none pl-0 d-lg-block">
                            <li class="active">
                                <a href="index.html" class="nav-link text-right">Home</a>
                            </li>
                            <li>
                                <a href="publication.html"" class="nav-link text-left">Publication</a>
                            </li>
                            <li>
                                <a href="group.html" class="nav-link text-left">Group</a>
                            </li>
                            <li>
                                <a href="resource.html" class="nav-link text-left">Resource</a>
                            </li>
                            <li>
                                <a href="perspective_students.html" class="nav-link text-left">Opening</a>
                            </li>
                            <!-- <li class="nav-item dropdown">
                                              <a class="nav-link dropdown-toggle" href="challenge.html" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                   Challenge
                                 </a>
                                          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                                           <a class="dropdown-item" href="challenge1.html">Tiny Object Detection Challenge</a>
                                           <a class="dropdown-item" href="challenge2.html">Image Restoration for UDC Challenge</a>
                                         </div>
                            </li>
                            <li>
                                <a href="callforpapers.html" class="nav-link text-left">Call for Papers</a>
                            </li>

                            <li>
                                <a href="speakers.html" class="nav-link text-left">Invited Speakers</a>
                            </li>

                            <li class="nav-item dropdown">
                                <a class="nav-link dropdown-toggle" href="challenge.html" id="navbarDropdown"
                                   role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                    Previous
                                </a>
                                <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                                    <a class="dropdown-item" href="https://yuqian2.wixsite.com/forlq">RLQ'19</a>
                                </div>
                            </li> -->
                        </ul>
                    </nav>

                </div>

            </div>
        </div>

    </div>

</div>



<div class="site-section">
    <div class="container">
        <div class="row">
            <div class="col-lg-12">
                <p>Our group actively publishes in the fields of machine learning, computer vision, and interdisciplinary data science. Below are a list of recent and selected papers. A mark * denotes the author to be a VITA student or Dr. Wang's mentee. An up-to-date full paper list can be found <a href="https://uc07af6a432ffbc8df367614624f.dl.dropboxusercontent.com/cd/0/inline2/A9gUQNwf4WYg0U89YbEa-Aw9O0AqsAT0svzCQV5DT6rvHdjnXfSrsfl7egFXs5ww6ibzuB-yAXZ6cGLarMTf_kQQIGDMxSs2lTOo5LIUcnKXD44tutt8DtUp3s18--VLfMKUTQyt5xR2yHnsVteIR4A2Lfwd8gKo8XSdbWhvrlh4oV4SkbLwZLf3zGLDW4bLQpQRBUFeisgJh8gmE0-kYH9-6SB2OgyNWQvKPx4rRoJkymdOegH6wD2A_zfrt6EZ3j5XmzM9_E82RRIjsmPPd_lviam894qd8CTBuCkXpVRVmjiYMtZaPN0Xox_mmqOUYVg1Cd8crIh_H_YkmiSehqsUdT7xQVfGXZuHXIO-3ZkUAg/file#">here</a>.</p>
                <div class="section-title" style="margin-bottom: 30px">
                    <h2>Journal Paper</h2>
                </div>
                <div class="trend-entry d-flex">
                    <div class="trend-contents">
                        <ul>
                            <li>Y. Yuan∗, W. Yang, W. Ren, J Liu, W. J. Scheirer, and Z. Wang, et. al., <b>“Advancing Image Understanding in Poor Visibility Environments: A Collective Benchmark Study”</b>, IEEE Transactions on Image Processing (TIP), 2020. <a href="https://arxiv.org/abs/1904.04474">[Paper]</a></li>
                            <li>M. Karimi, D. Wu, Z. Wang and Y. Shen, <b>“DeepAffinity: Interpretable Deep Learning of Compound-Protein Affinity through Unified Recurrent and Convolutional Neural Networks”</b>, Oxford Bioinformatics, 2019. <a href="https://academic.oup.com/bioinformatics/article/35/18/3329/5320555">[Paper]</a> <a href="https://github.com/Shen-Lab/DeepAffinity">[Code]</a></li>
                            <li>R. G. VidalMata, ... Y. Yuan*, J. Wu*, Z. Wang, ... et. al. <b>“Bridging the Gap Between Computational Photography and Visual Recognition”</b>, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2020. <a href="https://arxiv.org/abs/1901.09482">[Paper]</a></li>
                            <li>Y. Wang*, J. Shen*, T. Hu*, T. Nguyen, R. Baraniuk, Z. Wang, and Y. Lin, <b>“Dual Dynamic Inference: Enabling More Efficient, Adaptive and Controllable Deep Inference”</b>, IEEE Journal of Selected Topics in Signal Processing (JSTSP), 2020. <a href="https://arxiv.org/abs/1907.04523">[Paper]</a></li>
                            <li>B. Li*, W. Ren, D. Fu, D. Tao, D. Feng, W. Zeng, and Z. Wang, <b>“Benchmarking Single Image Dehazing and Beyond”</b>, IEEE Transactions on Image Processing (TIP), vol. 28, no. 1, pp. 492-505, 2019. <a href="https://arxiv.org/abs/1712.04143">[Paper]</a> <a href="https://sites.google.com/site/boyilics/website-builder/reside">[Project Page]</a></li>
                        </ul>
                    </div>
                </div>
                <div class="section-title" style="margin-bottom: 30px">
                    <h2>Conference Paper</h2>
                </div>
                <div class="trend-entry d-flex">
                    <div class="trend-contents">
                        <ul>
                            <li>H. Wang*, S. Gui, H. Yang, J. Liu, and Z. Wang, <b>“GAN Slimming: All-in-One GAN Compression by A Unified Optimization Framework”</b>, European Conference on Computer Vision (ECCV), 2020. (Spotlight Oral) [Paper][Code]</li>
                            <li>S. Yang*, Z. Wang, J. Liu, and Z. Guo, <b>“Deep Plastic Surgery: Robust and Controllable Image Editing with Human-Drawn Sketches”</b>, European Conference on Computer Vision (ECCV), 2020. <a href="https://arxiv.org/abs/2001.02890">[Paper]</a> [Code]</li>
                            <li>C. Li, T. Chen*, H. You, Z. Wang, and Y Lin, <b>“HALO: Hardware-Aware Learning to Optimize”</b>, European Conference on Computer Vision (ECCV), 2020. [Paper] [Code]</li>
                            <li>W. Chen*, Z. Yu, Z. Wang, and A. Anandkumar, <b>“Automated Synthetic-to-Real Generalization”</b>, International Conference on Machine Learning (ICML), 2020. <a href="https://proceedings.icml.cc/static/paper_files/icml/2020/4697-Paper.pdf">[Paper]</a> <a href="https://github.com/NVlabs/ASG">[Code]</a></li>
                            <li>X. Chen*, W. Chen*, T. Chen*, Y. Yuan*, C. Gong, K. Chen, and Z. Wang, <b>“Self-PU: Self Boosted and Calibrated Positive-Unlabeled Training”</b>, International Conference on Machine Learning (ICML), 2020. <a href="https://arxiv.org/abs/2006.11280">[Paper]</a> <a href="https://github.com/TAMU-VITA/Self-PU">[Code]</a></li>
                            <li>Y. You*, T. Chen*, Z. Wang, and Y. Shen, ”<b>When Does Self-Supervision Help Graph Convolutional Networks?”</b>, International Conference on Machine Learning (ICML), 2020. <a href="https://arxiv.org/abs/2006.09136">[Paper]</a> <a href="https://github.com/Shen-Lab/SS-GCNs">[Code]</a></li>
                            <li>R. Oftadeh, J. Shen*, Z. Wang, and D. Shell, <b>“Eliminating the Invariance on the Loss Landscape of Linear Autoencoders”</b>, International Conference on Machine Learning (ICML), 2020. <a href="https://proceedings.icml.cc/static/paper_files/icml/2020/3112-Paper.pdf">[Paper]</a> [Code]</li>
                            <li>Y. Fu, W. Chen*, H. Wang*, H. Li, Y. Lin, and Z. Wang, <b>“AutoGAN-Distiller: Searching to Compress Generative Adversarial Networks”</b>, International Conference on Machine Learning (ICML), 2020. <a href="https://arxiv.org/abs/2006.08198">[Paper]</a> <a href="https://github.com/TAMU-VITA/AGD">[Code]</a></li>
                            <li>R. Ardywibowo, S. Boluki, X. Gong*, Z. Wang, and X. Qian, <b>“NADS: Neural Architecture Distribution Search for Uncertainty Awareness”</b>, International Conference on Machine Learning (ICML), 2020. <a href="https://arxiv.org/abs/2006.06646">[Paper]</a> [Code]</li>
                            <li>Y. Zhao, X. Chen*, Y. Wang, C. Li, Y. Xie, Z. Wang, and Y. Lin, <b>“SmartExchange: Trading Higher-cost Memory Storage/Access for Lower-cost Computation”</b>, IEEE/ACM International Symposium on Computer Architecture (ISCA), 2020. <a href="https://arxiv.org/abs/2005.03403">[Paper]</a> [Code]</li>
                            <li>T. Chen*, S. Liu, S. Chang, Y. Cheng, L. Amini, and Z. Wang, <b>“Adversarial Robustness: From Self-Supervised Pretraining to Fine-Tuning”</b>, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020. <a href="http://sliu17.mysite.syr.edu/Self_Supervised_Meets_Adversarial_Robustness_CVPR20.pdf">[Paper]</a> <a href="https://github.com/TAMU-VITA/Adv-SS-Pretraining">[Code]</a></li>
                            <li>Z. Jiang*, B. Liu, S. Schulter, Z. Wang, and M. Chandraker, <b>“Peek-a-boo: Occlusion Reasoning in Indoor Scenes with Plane Representations”</b>, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020. (Oral) <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Jiang_Peek-a-Boo_Occlusion_Reasoning_in_Indoor_Scenes_With_Plane_Representations_CVPR_2020_paper.pdf">[Paper]</a> [Code]</li>
                            <li>Y. You*, T. Chen*, Z. Wang, and Y. Shen, <b>“L2-GCN: Layer-Wise and Learned Efficient Training of Graph Convolutional Networks”</b>, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020. <a href="https://arxiv.org/abs/2003.13606">[Paper]</a> <a href="https://github.com/TAMU-VITA/L2-GCN">[Code]</a></li>
                            <li>T. Hu*, T. Chen*, H. Wang*, and Z. Wang, <b>"Triple Wins: Boosting Accuracy, Robustness and Efficiency Together by Enabling Input-Adaptive Inference"</b>, International Conference on Learning Representations (ICLR), 2020. <a href="https://openreview.net/forum?id=rJgzzJHtDB">[Paper]</a> <a href="https://github.com/TAMU-VITA/triple-wins">[Code]</a></li>
                            <li>W. Chen*, X. Gong*, X. Liu, Q. Zhang, Y. Liu and Z. Wang, <b>"FasterSeg: Searching for Faster Real-time Semantic Segmentation"</b>, International Conference on Learning Representations (ICLR), 2020. <a href="https://openreview.net/forum?id=BJgqQ6NYvB">[Paper]</a> <a href="https://github.com/TAMU-VITA/FasterSeg">[Code]</a></li>
                            <li>H. Wang*, T. Chen*, Z. Wang, and K. Ma, <b>"I am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively"</b>, International Conference on Learning Representations (ICLR), 2020. <a href="https://openreview.net/forum?id=rJehNT4YPr">[Paper]</a> <a href="https://github.com/TAMU-VITA/MAD">[Code]</a></li>
                            <li>H. You, C. Li, P. Xu, Y. Fu, Y. Wang, X. Chen*, R. Baraniuk, Z. Wang, and Y. Lin, <b>"Drawing Early-Bird Tickets: Toward More Efficient Training of Deep Networks"</b>, International Conference on Learning Representations (ICLR), 2020. (Spotlight Oral) <a href="https://openreview.net/forum?id=BJxsrgStvr">[Paper]</a> <a href="https://github.com/RICE-EIC/Early-Bird-Tickets">[Code]</a></li>
                            <li>Z. Jiang*, Y. Wang*, X. Chen*, P. Xu, Y. Zhao, Y. Lin, and Z. Wang, <b>“E2-Train: Training State-of-the-art CNNs with Over 80% Energy Savings”</b>, Advances in Neural Information Processing Systems (NeurIPS), 2019. <a href="https://arxiv.org/abs/1910.13349">[Paper]</a> <a href="https://github.com/RICE-EIC/E2Train">[Code]</a></li>
                            <li>S. Gui, H. Wang*, H. Yang, C. Yu, Z. Wang, and J. Liu, <b>“Model Compression with Adversarial Robustness: A Unified Optimization Framework”</b>, Advances in Neural Information Processing Systems (NeurIPS), 2019. <a href="https://arxiv.org/abs/1902.03538">[Paper]</a> <a href="https://github.com/TAMU-VITA/ATMC">[Code]</a></li>
                            <li>Y. Cao, T. Chen*, Z. Wang, and Y. Shen, <b>“Learning to Optimize in Swarms”</b>, Advances in Neural Information Processing Systems (NeurIPS), 2019. <a href="https://arxiv.org/abs/1911.03787">[Paper]</a> <a href="https://github.com/Shen-Lab/LOIS">[Code]</a></li>
                            <li>S. Yang*, Z. Wang, Z Wang, N. Xu, J. Liu, and Z. Guo, <b>“Controllable Artistic Text Style Transfer via Shape-Matching GAN”</b>, IEEE International Conference on Computer Vision (ICCV), 2019. (Oral) <a href="https://arxiv.org/abs/1905.01354">[Paper]</a> <a href="https://github.com/TAMU-VITA/ShapeMatchingGAN">[Code]</a></li>
                            <li>Z. Wu*, K. Suresh*, P. Narayanan, H. Xu, H. Kwon, and Z. Wang, <b>“Delving into Robust Object Detection from Unmanned Aerial Vehicles: A Deep Nuisance Disentanglement Approach”</b>, IEEE International Conference on Computer Vision (ICCV), 2019. <a href="https://arxiv.org/abs/1908.03856">[Paper]</a> <a href="https://github.com/TAMU-VITA/UAV-NDFT">[Code]</a></li>
                            <li>X. Gong*, S. Chang, Y. Jiang*, and Z. Wang, <b>“AutoGAN: Neural Architecture Search for Generative Adversarial Networks”</b>, IEEE International Conference on Computer Vision (ICCV), 2019. <a href="https://arxiv.org/abs/1908.03835">[Paper]</a> <a href="https://github.com/TAMU-VITA/AutoGAN">[Code]</a></li>
                            <li>T. Chen*, S. Ding, J. Xie, Y. Yuan*, W. Chen*, Y. Yang, Z. Ren, and Z. Wang, <b>“ABD-Net: Attentive but Diverse Person Re-Identification”</b>, IEEE International Conference on Computer Vision (ICCV), 2019. <a href="https://arxiv.org/abs/1908.01114">[Paper]</a> <a href="https://github.com/TAMU-VITA/ABD-Net">[Code]</a></li>
                            <li>O. Kupyn, T. Martyniuk, J. Wu*, and Z. Wang, <b>“DeblurGAN-v2: Deblurring (Orders-of-Magnitude) Faster and Better”</b>, IEEE International Conference on Computer Vision (ICCV), 2019. <a href="https://arxiv.org/abs/1908.03826">[Paper]</a> <a href="https://github.com/TAMU-VITA/DeblurGANv2">[Code]</a></li>
                            <li>E. Ryu, J. Liu, S. Wang*, X. Chen*, Z. Wang, and W. Yin, <b>“Plug-and-Play Methods Provably Converge with Properly Trained Denoisers”</b>, International Conference on Machine Learning (ICML), 2019. <a href="https://arxiv.org/abs/1905.05406">[Paper]</a> <a href="https://github.com/TAMU-VITA/Provable_Plug_and_Play">[Code]</a></li>
                            <li>W. Chen*, Z. Jiang*, Z. Wang, K. Cui, and X. Qian, <b>“Collaborative Global-Local Networks for Memory-Efficient Segmentation of Ultra-high Resolution Images”</b>, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019. (Oral) <a href="https://arxiv.org/abs/1905.06368">[Paper]</a> <a href="https://github.com/TAMU-VITA/GLNet">[Code]</a></li>
                            <li>S. Li, I. B. Araujo*, W. Ren, Z. Wang, E. K. Tokuda*, R. Hirata, R. Cesar, J. Zhang, X. Guo, and X. Cao, <b>“Single Image Deraining: A Comprehensive Benchmark Analysis”</b>, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019. <a href="https://arxiv.org/abs/1903.08558">[Paper]</a> <a href="https://github.com/lsy17096535/Single-Image-Deraining">[Code]</a></li>
                            <li>J. Liu, X. Chen*, Z. Wang, and W. Yin, <b>“ALISTA: Analytic Weights Are As Good As Learned Weights in LISTA”</b>, International Conference on Learning Representations (ICLR), 2019. <a href="https://openreview.net/forum?id=B1lnzn0ctQ">[Paper]</a> <a href="https://github.com/TAMU-VITA/ALISTA">[Code]</a></li>
                            <li>B. Li*, W. Ren, D. Fu, D. Tao, D. Feng, W. Zeng, and Z. Wang, <b>“Benchmarking Single Image Dehazing and Beyond”</b>, IEEE Transactions on Image Processing (TIP), vol. 28, no. 1, pp. 492-505, 2019.</li>
                            <li>X. Chen*, J. Liu, Z. Wang, and W. Yin, <b>“Theoretical Linear Convergence of Unfolded ISTA and Its Practical Weights and Thresholds”</b>, Advances in Neural Information Processing Systems (NeurIPS), 2018. (Spotlight Oral) <a href="http://papers.nips.cc/paper/8120-theoretical-linear-convergence-of-unfolded-ista-and-its-practical-weights-and-thresholds">[Paper]</a> <a href="https://github.com/TAMU-VITA/LISTA-CPSS">[Code]</a></li>
                            <li>N. Bansal*, X. Chen*, and Z. Wang, <b>“Can We Gain More from Orthogonality Regularizations in Training Deep CNNs?”</b>, Advances in Neural Information Processing Systems (NeurIPS), 2018. <a href="http://papers.nips.cc/paper/7680-can-we-gain-more-from-orthogonality-regularizations-in-training-deep-networks">[Paper]</a> <a href="https://github.com/TAMU-VITA/Orthogonality-in-CNNs">[Code]</a></li>
                            <li>Z. Wu*, Z. Wang, Z. Wang, and H. Jin, <b>“Towards Privacy-Preserving Visual Recognition via Adversarial Training: A Pilot Study”</b>, European Conference on Computer Vision (ECCV), 2018. <a href="https://openaccess.thecvf.com/content_ECCV_2018/html/Zhenyu_Wu_Towards_Privacy-Preserving_Visual_ECCV_2018_paper.html">[paper]</a> <a href="https://github.com/TAMU-VITA/Privacy-AdversarialLearning">[Code]</a></li>
                            <li>Wu*, Y. Wang*, Z. Wu*, Z. Wang, A. Veeraraghavan, and Y. Lin, <b>“Deep k-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions”</b>, International Conference on Machine Learning (ICML), 2018. <a href="http://proceedings.mlr.press/v80/wu18h.html">[Paper]</a> <a href="https://github.com/TAMU-VITA/Deep-K-Means-pytorch">[Code]</a></li>
                        </ul>
                       
                    </div>
                </div>
            </div>

        </div>
        
<!-- END section -->


<div class="footer">
    <div class="container">
        <div class="row">
            <div class="col-12">
                <div class="copyright">
                    <p>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        Copyright &copy;<script>document.write(new Date().getFullYear());</script>
                        All rights reserved | Built upon <a
                            href="https://colorlib.com" target="_blank">Colorlib</a>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        </p>
                        
                </div>
            </div>
        </div>
    </div>
</div>

</div>
<!-- .site-wrap -->


<!-- loader -->
<!-- <div id="loader" class="show fullscreen">
    <svg class="circular" width="48px" height="48px">
        <circle class="path-bg" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke="#eeeeee"/>
        <circle class="path" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke-miterlimit="10"
                stroke="#ff5e15"/>
    </svg>
</div> -->

<script src="js/jquery-3.3.1.min.js"></script>
<script src="js/jquery-migrate-3.0.1.min.js"></script>
<script src="js/jquery-ui.js"></script>
<script src="js/popper.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/owl.carousel.min.js"></script>
<script src="js/jquery.stellar.min.js"></script>
<script src="js/jquery.countdown.min.js"></script>
<script src="js/bootstrap-datepicker.min.js"></script>
<script src="js/jquery.easing.1.3.js"></script>
<script src="js/aos.js"></script>
<script src="js/jquery.fancybox.min.js"></script>
<script src="js/jquery.sticky.js"></script>
<script src="js/jquery.mb.YTPlayer.min.js"></script>

<script src="js/main.js"></script>

</body>

</html>
