<!DOCTYPE html>
<html lang="en">

<head>
    <title>VITA</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">


    <link href="https://fonts.googleapis.com/css?family=B612+Mono|Cabin:400,700&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="fonts/icomoon/style.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
          integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">

    <link rel="stylesheet" href="css/jquery-ui.css">
    <link rel="stylesheet" href="css/owl.carousel.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">

    <link rel="stylesheet" href="css/jquery.fancybox.min.css">

    <link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">

    <link rel="stylesheet" href="css/aos.css">
    <link href="css/jquery.mb.YTPlayer.min.css" media="all" rel="stylesheet" type="text/css">

    <link rel="stylesheet" href="css/style.css">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->


</head>

<body data-spy="scroll" data-target=".site-navbar-target" data-offset="300">

<div class="site-wrap">

    <div class="site-mobile-menu site-navbar-target">
        <div class="site-mobile-menu-header">
            <div class="site-mobile-menu-close mt-3">
                <span class="icon-close2 js-menu-toggle"></span>
            </div>
        </div>
        <div class="site-mobile-menu-body"></div>
    </div>

    <div class="header-top">
        <div class="container" style="padding:20px">
            <div class="row align-items-center">
                <!-- <div class="col-12 col-lg-6 d-flex"> -->
                    <img src="./logo.png" width="15%">
                    <a class="ml-auto site-logo">
                       
                             &nbsp&nbsp<b style="color: rgb(71, 71, 71)">V</b>isual <b style="color: rgb(71, 71, 71)">I</b>nformatics Group @ University of <b style="color: rgb(71, 71, 71)">T</b>exas at <b style="color: rgb(71, 71, 71)">A</b>ustin
                    </a>
                    <a href="#"
                       class="ml-auto d-inline-block d-lg-none site-menu-toggle js-menu-toggle text-black"><span
                            class="icon-menu h3"></span></a>

                <!-- </div> -->
                <!-- <div class="col-12 col-lg-6 ml-auto d-flex">
                    <div class="ml-md-auto top-social d-none d-lg-inline-block">
                        <a href="#" class="d-inline-block p-3"> </a>
                        <a href="#" class="d-inline-block p-3"> </a>
                        <a href="#" class="d-inline-block p-3"> </a>
                    </div>

                </div> -->
                <!--          <div class="col-6 d-block d-lg-none text-right">-->

            </div>
        </div>
    </div>

    
    <div class="site-navbar py-2 js-sticky-header site-navbar-target d-none pl-0 d-lg-block" role="banner">

        <div class="container" style="padding-right=10%">
            <div class="d-flex align-items-right">
                <!-- <div class="mr-auto">
                    <a href="index.html">
                       <img src="./logo.png" width="10%"/>
                             &nbsp&nbsp<b>V</b>isual <b>I</b>nformatics Group @ University of <b>T</b>exas at <b>A</b>ustin
                    </a>
                </div> -->
                <div class="ml-auto">
                    <nav class="site-navigation position-relative text-right" role="navigation">
                        <ul class="site-menu main-menu js-clone-nav mr-auto d-none pl-0 d-lg-block">
                            <li class="active">
                                <a href="index.html" class="nav-link text-right">Home</a>
                            </li>
                            <li>
                                <a href="research.html" class="nav-link text-left">PI & Research</a>
                            </li>
                            <li>
                                <a href="publication.html" class="nav-link text-left">Publication</a>
                            </li>
                            <li>
                                <a href="group.html" class="nav-link text-left">Group</a>
                            </li>
                            <li>
                                <a href="resource.html" class="nav-link text-left">Resource</a>
                            </li>
                            <li>
                                <a href="prospective_students.html" class="nav-link text-left">Opening</a>
                            </li>
                            <!-- <li class="nav-item dropdown">
                                              <a class="nav-link dropdown-toggle" href="challenge.html" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                   Challenge
                                 </a>
                                          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                                           <a class="dropdown-item" href="challenge1.html">Tiny Object Detection Challenge</a>
                                           <a class="dropdown-item" href="challenge2.html">Image Restoration for UDC Challenge</a>
                                         </div>
                            </li>
                            <li>
                                <a href="callforpapers.html" class="nav-link text-left">Call for Papers</a>
                            </li>

                            <li>
                                <a href="speakers.html" class="nav-link text-left">Invited Speakers</a>
                            </li>

                            <li class="nav-item dropdown">
                                <a class="nav-link dropdown-toggle" href="challenge.html" id="navbarDropdown"
                                   role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                    Previous
                                </a>
                                <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                                    <a class="dropdown-item" href="https://yuqian2.wixsite.com/forlq">RLQ'19</a>
                                </div>
                            </li> -->
                        </ul>
                    </nav>

                </div>

            </div>
        </div>

    </div>

</div>



<div class="site-section">
    <div class="container">
        <div class="row">
            <div class="col-lg-12">

                
                <div class="section-title" style="margin-bottom:20px">
                    <h2>About PI</h2>
                </div>
                <div class="trend-entry d-flex">
                    <div class="trend-contents">
                        <p>Professor Zhangyang “Atlas” Wang <a href="https://scholar.google.com/citations?user=pxFyKAIAAAAJ&hl=en">[Google Scholar]</a> is currently the Jack Kilby/Texas Instruments Endowed Assistant Professor in the Chandra Family Department of Electrical and Computer Engineering at The University of Texas at Austin. He is also a faculty member of UT Computer Science (GSC) <a href="https://csrankings.org/"> [CSRankings]</a>, and the Oden Institute CSEM program. Meanwhile, in a part-time role, he serves as the Director of AI Research & Technology for <a href="https://picsart.com/">Picsart</a>, developing the next-generation AI-powered tools for visual creative editing. During 2021 - 2022, he held  a visiting researcher position at Amazon Search. From 2017 to 2020, he was an Assistant Professor of Computer Science and Engineering, at the Texas A&M University. He received his Ph.D. degree in ECE from UIUC in 2016, advised by Professor Thomas S. Huang; and his B.E. degree in EEIS from USTC in 2012. </p>

                        <p>Prof. Wang has broad research interests spanning from the theory to the application aspects of machine learning (ML). At present, his core research mission is to leverage, understand and expand the role of  <b style="color:rgb(71, 71, 71)">sparsity</b>, from classical optimization to modern neural networks, whose impacts span over many important topics such as efficient training/inference/transfer (especially, of large foundation models), robustness and trustworthiness, learning to optimize (L2O), generative AI, and graph learning. His research is gratefully supported by NSF, DARPA, ARL, ARO, IARPA, DOE, as well as dozens of industry and university grants. Prof. Wang co-founded the new <a href="https://cpal.cc/">Conference on Parsimony and Learning (CPAL)</a> and serves as its inaugural Program Chair. He is/was an elected technical committee member of IEEE MLSP and IEEE CI; an associate editor of IEEE TCSVT (receiving the 2020 Best Associate Editor Award); and regularly serves as area chairs, invited speakers, tutorial/workshop organizers, various panelist positions and reviewers. He is an ACM Distinguished Speaker and an IEEE senior member.</p>

                        <p>Prof. Wang has received many research awards, including an NSF CAREER Award, an ARO Young Investigator Award, an IEEE AI's 10 To Watch Award, an INNS Aharon Katzir Young Investigator Award, a Google Research Scholar award, an IBM Faculty Research Award, a J. P. Morgan Faculty Research Award, an Amazon Research Award, an Adobe Data Science Research Award, a Meta Reality Labs Research Award, and two Google TensorFlow Model Garden Awards. His team has won the Best Paper Award from the inaugural Learning on Graphs (LoG) Conference 2022; and has also won five research competition prizes from CVPR/ICCV/ECCV since 2018. He feels most proud of being surrounded by some of the world's most brilliant students: his Ph.D. students include winners of seven prestigious fellowships (NSF GRFP, IBM, Apple, Adobe, Amazon, Qualcomm, and Snap), among many other honors.</p>
                    </div>
                </div>



                <div class="section-title" style="margin-bottom:20px">
                    <h2>About Our Research</h2>
                </div>
                <div class="trend-entry d-flex">
                    <div class="trend-contents">


                     <p>At VITA group, we have <b style="color:rgb(71, 71, 71)">unusually broad, and forever-evolving</b> research interests spanning from the <b style="color:rgb(71, 71, 71)">theory</b>  to the <b style="color:rgb(71, 71, 71)">application</b> aspects of machine learning (ML). Our current "research keywords" include, but are not limited to:  sparsity (from classical optimization to modern neural networks); efficient training, inference or transfer (especially, of large foundation models); robustness and trustworthiness; learning to optimize (L2O); generative AI; graph learning, and more. Below, we describe a few organized themes that are driving our group's latest efforts.</p>
                    </ul>

                        <h4>Theme 1: Sparse Neural Networks and Efficient Learning</h4>
                        <p>
                           Substantial efforts have been devoted to scaling deep NNs to enormous sizes. Sparse NNs, whose large portions of parameters (or activations, gradients, etc.) are zero, have been promising to address those gaps. Early approaches first train dense NNs and then prune the trained NNs. Those methods significantly reduce the inference complexity yet cost even greater computational resources and memory footprints at training. We have instead explored the fresh prospect of directly training smaller, sparse NNs in place of the large dense models without sacrificing task performance. Our group has contributed many pioneering and well-recognized works to laying both empirical and theoretical foundations for sparse NNs’ efficiency, optimization, and generalization, in both TinyML and large foundation model (e.g. LLM) applications. We also prepared a <a href="https://arxiv.org/abs/2302.02596">short handbook for sparse NN researchers</a>.
                        </p>

                        <b style="color:rgb(68, 68, 68)"><i>Selected Notable Works:</i></b>
                        <li>D. Hoang*, S. Liu*, R. Marculescu, and Z. Wang, <b style="color:rgb(71, 71, 71)">"Revisiting Pruning at Initialization Through the Lens of Ramanujan Graph”</b>, International Conference on Learning Representations (ICLR), 2023. (Oral) <a href="https://openreview.net/forum?id=uVcDssQff_">[Paper]</a> <a href="https://github.com/VITA-Group/ramanujan-on-pai">[Code] </a> </li>
                        <li>S. Liu*, T. Chen*, Z. Zhang*, X. Chen*, T. Huang, A. Jaiswal*, and Z. Wang, <b style="color:rgb(71, 71, 71)">"Sparsity May Cry: Let Us Fail (Current) Sparse Neural Networks Together!”</b>, International Conference on Learning Representations (ICLR), 2023. (Spotlight) <a href="https://openreview.net/forum?id=J6F3lLg4Kdp">[Paper]</a> <a href="https://github.com/VITA-Group/SMC-Bench">[Code] </a>  </li>
                        <li>H. Yang*, and Z. Wang, <b style="color:rgb(71, 71, 71)">"On the Neural Tangent Kernel Analysis of Randomly Pruned Neural Networks”</b>, International Conference on Artificial Intelligence and Statistics (AISTATS), 2023. <a href="https://arxiv.org/abs/2203.14328">[Paper]</a> <a href="https://github.com/VITA-Group/Random-Pruning-NTK">[Code]</a> </li>
                        <li>T. Chen*, J. Frankle, S. Chang, S. Liu, Y. Zhang, Z. Wang, and M. Carbin, <b style="color:rgb(71, 71, 71)">“The Lottery Ticket Hypothesis for Pre-trained BERT Networks”</b>, Advances in Neural Information Processing Systems (NeurIPS), 2020. <a href="https://arxiv.org/abs/2007.12223">[Paper]</a> <a href="https://github.com/VITA-Group/BERT-Tickets">[Code]</a></li>
                         <br>


                        <h4>Theme 2: Emerging Models and New Architectures </h4>
                        <p>
                           We are devoted to studying emerging model families that promise to become future “universal” workhorses or "foundational models": two such examples are transformers (especially LLMs) and graph neural networks, and many projects here are owing to our close collaboration with industry leaders. We are meanwhile enthusiastic about AutoML, on both consolidating its theoretical underpinnings ("why choosing this model, not that one?") and broadening its practical applicability ("what more can be automated, and how to do it better?"). State-of-the-art ML systems consist of complex pipelines with multiplied design choices. We see AutoML as a central hub in addressing those design challenges; it also proves to be a powerful tool for understanding many ad-hoc choices of network architectures or hyperparameters (often aided by the deep learning theory). 
                        </p>

                        <b style="color:rgb(68, 68, 68)"><i>Selected Notable Works:</i></b>
                        <li>P. Wang*, R. Panda, L. Hennigen, P. Greengard, L. Karlinsky, R. Feris, D. Cox, Z. Wang, and Y. Kim, <b style="color:rgb(71, 71, 71)">"Learning to Grow Pretrained Models for Efficient Transformer Training”</b>, International Conference on Learning Representations (ICLR), 2023. (Spotlight) <a href="https://openreview.net/forum?id=cDYRS5iZ16f">[Paper]</a> <a href="https://github.com/VITA-Group/LiGO">[Code] </a> </li>
                        <li>P. Wang*, W. Zheng*, T. Chen*, and Z. Wang, <b style="color:rgb(71, 71, 71)">“Anti-Oversmoothing in Deep Vision Transformers via the Fourier Domain Analysis: From Theory to Practice”</b>, International Conference on Learning Representations (ICLR), 2022. <a href="https://openreview.net/forum?id=O476oWmiNNp">[Paper]</a> <a href="https://github.com/VITA-Group/ViT-Anti-Oversmoothing">[Code]</a></li>
                        <li>W. Chen*, X. Gong*, and Z. Wang, <b style="color:rgb(71, 71, 71)">“Neural Architecture Search on ImageNet in Four GPU Hours: A Theoretically Inspired Perspective”</b>, International Conference on Learning Representations (ICLR), 2021. <a href="https://openreview.net/forum?id=Cnon5ezMHtu">[Paper]</a> <a href="https://github.com/VITA-Group/TENAS">[Code]</a> 
                        <li>Y. You*, T. Chen*, Y. Sui, T. Chen, Z. Wang, and Y. Shen, <b style="color:rgb(71, 71, 71)">“Graph Contrastive Learning with Augmentations”</b>, Advances in Neural Information Processing Systems (NeurIPS), 2020. <a href="https://arxiv.org/abs/2010.13902">[Paper]</a> <a href="https://github.com/VITA-Group/GraphCL">[Code]</a></li>
                         <br>


                        <h4>Theme 3: Learning to Optimize (L2O) </h4>
                        <p>
                            L2O is an emerging paradigm that leverages ML to automatically develop an optimization algorithm. It demonstrates many practical benefits including faster convergence and better solution quality. Over the past five years, we have developed an ever-growing line of pioneering L2O works that significantly expand both rigorous theories (L2O convergence, worst-case/average-case generalization, adaptation, uncertainty quantification, and interpretability), and practical adoption (inverse problems in computational sensing/imaging, large model training, private training, protein docking, AI for finance, among others). Please refer to the <a href="https://jmlr.org/papers/volume23/21-0308/21-0308.pdf">L2O Primer</a> and <a href="https://github.com/VITA-Group/Open-L2O">Open L2O toolbox</a> that we presented for this community.
                        </p>

                        <b style="color:rgb(68, 68, 68)"><i>Selected Notable Works:</i></b>
                        <li>J. Yang, T. Chen*, M. Zhu*, F. He, D. Tao, Y. Liang, and Z. Wang, <b style="color:rgb(71, 71, 71)">"Learning to Generalize Provably in Learning to Optimize”</b>, International Conference on Artificial Intelligence and Statistics (AISTATS), 2023. <a href="https://arxiv.org/abs/2302.11085">[Paper]</a> <a href="https://github.com/VITA-Group/Open-L2O/tree/main/Model_Free_L2O/L2O-Entropy">[Code] </a> </li>
                        <li>(α-β) T. Chen*, X. Chen*, W. Chen*, H. Heaton, J. Liu, and Z. Wang, W. Yin, <b style="color:rgb(71, 71, 71)">“Learning to Optimize: A Primer and A Benchmark”</b>, Journal of Machine Learning Research (JMLR), 2022. <a href="https://jmlr.org/papers/v23/21-0308.html">[Paper]</a> <a href="https://github.com/VITA-Group/Open-L2O">[Code]</a></li> 
                        <li>W. Zheng*, T. Chen*, T. Hu*, and Z. Wang, <b style="color:rgb(71, 71, 71)">“Symbolic Learning to Optimize: Towards Interpretability and Scalability”</b>, International Conference on Learning Representations (ICLR), 2022. <a href="https://openreview.net/forum?id=ef0nInZHKIC">[Paper]</a> <a href="https://github.com/VITA-Group/Symbolic-Learning-To-Optimize">[Code]</a></li>
                        <li>J. Liu, X. Chen*, Z. Wang, and W. Yin, <b style="color:rgb(71, 71, 71)">“ALISTA: Analytic Weights Are As Good As Learned Weights in LISTA”</b>, International Conference on Learning Representations (ICLR), 2019. <a href="https://openreview.net/forum?id=B1lnzn0ctQ">[Paper]</a> <a href="https://github.com/TAMU-VITA/ALISTA">[Code]</a></li>
                         <br>


                        <h4>Theme 4: 2D/3D Visual Sythesis, Editing, and Enhancement</h4>
                        <p>
                            Our group's earlier (pre-2021) work includes several influential algorithms for image enhancement and editing “in the wild,” many of which are based on Generative Adversarial Networks (GANs). We pioneered a few innovative GAN architectural designs (TransGAN, DeblurGAN-v2, EnlightenGAN, AutoGAN) that are now widely adopted by the community. More recently (post-2021), we have steered our focus to two new areas: (i) 3D reconstruction and novel view synthesis, via Neural Radiance Fields (NeRF); (2) the new generation of multi-modality GenAI, leveraging the latest workhorse of diffusion models (text2image, text2video, text-to-3D, etc.)
                        </p>


                        <b style="color:rgb(68, 68, 68)"><i>Selected Notable Works:</i></b>
                        <li>L. Khachatryan, A. Movsisyan, V. Tadevosyan, R. Henschel, Z. Wang, S. Navasardyan, and H. Shi, <b style="color:rgb(71, 71, 71)">"Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators”</b>, arXiv preprint arXiv:2303.13439. <a href="https://arxiv.org/abs/2303.13439">[Paper]</a> <a href="https://github.com/Picsart-AI-Research/Text2Video-Zero">[Code] </a> </li>
                        <li>M. Varma*, P. Wang*, X. Chen*, T. Chen*, S. Venugopalan, and Z. Wang, <b style="color:rgb(71, 71, 71)">"Is Attention All That NeRF Needs?”</b>, International Conference on Learning Representations (ICLR), 2023. <a href="https://openreview.net/forum?id=xE-LtsE-xx">[Paper]</a> <a href="https://github.com/VITA-Group/GNT">[Code]</a> </li>
                        <li>D. Xu*, Y. Jiang*, P. Wang*, Z. Fan*, H. Shi, and Z. Wang, <b style="color:rgb(71, 71, 71)">“SinNeRF: Training Neural Radiance Field on Complex Scenes from a Single Image”</b>, European Conference on Computer Vision (ECCV), 2022. <a href="https://arxiv.org/abs/2204.00928">[Paper]</a> <a href="https://vita-group.github.io/SinNeRF/">[Code] </a> </li>
                        <li>Y. Jiang*, S. Chang, and Z. Wang, <b style="color:rgb(71, 71, 71)">“TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can Scale Up”</b>, Advances in Neural Information Processing Systems (NeurIPS), 2021. <a href="https://arxiv.org/abs/2102.07074">[Paper]</a> <a href="https://github.com/VITA-Group/TransGAN">[Code]</a></li>
                         <br>


                        <h4>Theme 5: Responsible Machine Learning</h4>
                        <p>
                            As ML systems (in particular, computer vision and LLM) are influencing all facets of our daily life, it is now commonplace to see evidence on the untrustworthiness or harmful impacts of ML systems in high-stake environments. We have strived to build ML algorithms that are resilient to various environment degradations, perturbations, adversarial attacks, and privacy threats - as overviewed in our  <a href="https://dl.acm.org/doi/full/10.1145/3551385">ML Safety Primer</a>. We have also keen on developing AI4sicnece (protein, medical image, material science), and AI for the Common Good (our <a href="https://bridgingbarriers.utexas.edu/good-systems/projects/being-watched-embedding-ethics-in-public-cameras">Good Systems</a> project)
                        </p>

                        <b style="color:rgb(68, 68, 68)"><i>Selected Notable Works:</i></b>
                        <li>R. Cai*, Z. Zhang*, and Z. Wang, <b style="color:rgb(71, 71, 71)">“Robust Weight Signatures: Gaining Robustness as Easy as Patching Weights?”</b>, International Conference on Machine Learning (ICML), 2023. <a href="https://arxiv.org/abs/2302.12480">[Paper]</a> <a href="https://github.com/VITA-Group/Robust_Weight_Signatures">[Code] </a>  </li>
                        <li>T. Chen*, C. Gong, D. Diaz, X. Chen*, J. Wells, Q. Liu, Z. Wang, A. Ellington, A. Dimakis, and A. Klivans, <b style="color:rgb(71, 71, 71)">"HotProtein: A Novel Framework for Protein Thermostability Prediction and Editing”</b>, International Conference on Learning Representations (ICLR), 2023. <a href="https://openreview.net/forum?id=YDJRFWBMNby">[Paper]</a> <a href="https://github.com/VITA-Group/HotProtein">[Code]</a> </li>
                        <li>H. Wang*, C. Xiao, J. Kossaifi, Z. Yu, A. Anandkumar, and Z. Wang, <b style="color:rgb(71, 71, 71)">“AugMax: Adversarial Composition of Random Augmentations for Robust Training”</b>, Advances in Neural Information Processing Systems (NeurIPS), 2021. <a href="https://arxiv.org/abs/2110.13771">[Paper]</a> <a href="https://github.com/VITA-Group/AugMax">[Code]</a></li>
                       <li>Z. Wu*, H. Wang*, Z. Wang, H. Jin, and Z. Wang, <b style="color:rgb(71, 71, 71)">“Privacy-Preserving Deep Action Recognition: An Adversarial Learning Framework and A New Dataset”</b>, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2020. <a href="https://ieeexplore.ieee.org/abstract/document/9207852">[Paper]</a> <a href="https://github.com/VITA-Group/PA-HMDB51">[Code]</a></li>
                         <br>
                        <!-- <br> -->
                        <h5><a href="./prospective_students.html">Prospective Students Shall Read More...</a></h5>
                    </div>
                </div>




            <div class="section-title" style="padding-top: 20px">
                <h2>Sponsor</h2>
            </div>
            <div class="trend-entry d-flex">
                <div class="row justify-content-md-center">
                    <div>
                        <img src="./123.png" width="100%"/>
                    </div>
                </div>
            </div>
        </div>

        </div>
    </div>

        
<!-- END section -->


<div class="footer">
    <div class="container">
        <div class="row">
            <div class="col-12">
                <div class="copyright">
                    <p>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        Copyright &copy;<script>document.write(new Date().getFullYear());</script>
                        All rights reserved | Built upon <a
                            href="https://colorlib.com" target="_blank">Colorlib</a>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        </p>
                        
                </div>
            </div>
        </div>
    </div>
</div>

</div>
<!-- .site-wrap -->


<!-- loader -->
<!-- <div id="loader" class="show fullscreen">
    <svg class="circular" width="48px" height="48px">
        <circle class="path-bg" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke="#eeeeee"/>
        <circle class="path" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke-miterlimit="10"
                stroke="#ff5e15"/>
    </svg>
</div> -->

<script src="js/jquery-3.3.1.min.js"></script>
<script src="js/jquery-migrate-3.0.1.min.js"></script>
<script src="js/jquery-ui.js"></script>
<script src="js/popper.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/owl.carousel.min.js"></script>
<script src="js/jquery.stellar.min.js"></script>
<script src="js/jquery.countdown.min.js"></script>
<script src="js/bootstrap-datepicker.min.js"></script>
<script src="js/jquery.easing.1.3.js"></script>
<script src="js/aos.js"></script>
<script src="js/jquery.fancybox.min.js"></script>
<script src="js/jquery.sticky.js"></script>
<script src="js/jquery.mb.YTPlayer.min.js"></script>

<script src="js/main.js"></script>

</body>

</html>
